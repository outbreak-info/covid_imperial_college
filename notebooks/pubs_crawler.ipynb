{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiral Report crawler\n",
    "\n",
    "Imperial College London has an open access repository, called Spiral. \n",
    "Spiral hosts the reports with more of the metadata exposed than is exposed in the public website access for the reports. Trying to pull the metadata from the public website links requires multiple pages with multiple levels of parsing. For the reports, it's easier to use the data pulled from spiral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Curation Object (ie- the curatedBy object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_curationObject():\n",
    "    now = datetime.now()\n",
    "    curatedBy = {\n",
    "    \"@type\": \"Organization\",\n",
    "    'identifier': 'imperialcollege',\n",
    "    'url': 'http://www.imperial.ac.uk/mrc-global-infectious-disease-analysis/covid-19/covid-19-reports/',\n",
    "    \"name\": \"MRC Centre for Global Infectious Disease Analysis\",\n",
    "    \"affiliation\": [\"Imperial College London\"],\n",
    "    \"curationDate\":now.strftime(\"%Y-%m-%d\")\n",
    "    }    \n",
    "    return(curatedBy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Spiral for COVID-19 reports and parse the result into a list of urls of the individual report pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report_links(reports_url):\n",
    "    recordlist = requests.get(reports_url)\n",
    "    spiralbase = \"https://spiral.imperial.ac.uk:8443/\"\n",
    "    parsedrecordlist = BeautifulSoup(recordlist.text, \"html.parser\")\n",
    "    urlstable = parsedrecordlist.findAll(\"table\")[0]\n",
    "    urlstublist = urlstable.findAll(\"a\")\n",
    "    url_list = []\n",
    "    for eachlink in urlstublist:\n",
    "        tmpurl = spiralbase+eachlink.get(\"href\")\n",
    "        url_list.append(tmpurl)\n",
    "    return(url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're dealing with html files, create a function to get content for a specific tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_content(metacontentfield):\n",
    "    if len(metacontentfield) == 1:\n",
    "        metacontentlist = metacontentfield[0].get(\"content\")\n",
    "    else:\n",
    "        metacontentlist = []\n",
    "        for eachitem in metacontentfield:\n",
    "            metaitem = eachitem.get(\"content\")\n",
    "            metacontentlist.append(metaitem)\n",
    "    return(metacontentlist)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull content from the appropriate meta data tags and format it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pub_meta(soupobject):\n",
    "    urlfield = soupobject.findAll(\"meta\", {\"name\":\"citation_pdf_url\"})\n",
    "    url = get_meta_content(urlfield)\n",
    "    titlefield = soupobject.findAll(\"meta\", {\"name\":\"citation_title\"})\n",
    "    title = get_meta_content(titlefield)\n",
    "    datePublishedfield = soupobject.findAll(\"meta\", {\"name\":\"citation_date\"})\n",
    "    datePublished = get_meta_content(datePublishedfield)\n",
    "    abstractfield = soupobject.findAll(\"meta\", {\"name\":\"DCTERMS.abstract\"})\n",
    "    abstract = get_meta_content(abstractfield)\n",
    "    defaultidurlfield = soupobject.findAll(\"meta\", {\"scheme\":\"DCTERMS.URI\"})\n",
    "    defaultid = get_meta_content(defaultidurlfield)\n",
    "    tmpdict = {\n",
    "        \"@context\": {\n",
    "        \"schema\": \"http://schema.org/\",\n",
    "        \"outbreak\": \"https://discovery.biothings.io/view/outbreak/\"\n",
    "        },\n",
    "        \"@type\": \"Publication\",\n",
    "        \"journalName\": \"Imperial College London\",\n",
    "        \"journalNameAbbreviation\": \"imperialcollege\",\n",
    "        \"publicationType\": \"Report\", \n",
    "        \"abstract\":abstract,\n",
    "        \"name\":title,\n",
    "        \"datePublished\":datePublished,\n",
    "        \"url\":url,\n",
    "        \"identifier\":defaultid\n",
    "    }\n",
    "    keywordsfield = soupobject.findAll(\"meta\", {\"name\":\"DC.subject\"})\n",
    "    if len(keywordsfield)>0:\n",
    "        keywordsobject = get_meta_content(keywordsfield)\n",
    "        tmpdict[\"keywords\"] = keywordsobject\n",
    "\n",
    "    licensefield = soupobject.findAll(\"meta\", {\"name\":\"DC.rights\"})\n",
    "    if len(licensefield)>0:\n",
    "        license = get_meta_content(licensefield)\n",
    "        tmpdict[\"license\"] = license\n",
    "        \n",
    "    identifiersfield = soupobject.findAll(\"meta\", {\"name\":\"DC.identifier\"})\n",
    "    for eachitem in identifiersfield:\n",
    "        eachitemcontent = eachitem.get(\"content\")\n",
    "        if \"doi\" in eachitemcontent:\n",
    "            doi = eachitemcontent.replace(\"https://doi.org/\",\"\")\n",
    "            tmpdict[\"identifier\"] = \"icl_\"+doi.split('/', 1)[-1]\n",
    "            tmpdict[\"doi\"] = doi\n",
    "        elif \"10.\" in eachitemcontent:\n",
    "            doi = eachitemcontent\n",
    "            tmpdict[\"identifier\"] = \"icl_\"+doi.split('/', 1)[-1]\n",
    "            tmpdict[\"doi\"] = doi\n",
    "    tmpdict['_id'] = tmpdict[\"identifier\"]\n",
    "    return(tmpdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Author information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_authors(soupobject):\n",
    "    authorsfield = soupobject.findAll(\"meta\", {\"name\":\"citation_author\"})\n",
    "    authors = get_meta_content(authorsfield)\n",
    "    authorlist = []\n",
    "    for eachauthor in authors:\n",
    "        authparse = eachauthor.split(\",\")\n",
    "        if (len(authparse) == 2) and len(authparse[1])<3:\n",
    "            authdict = {'@type': 'outbreak:Person', 'affiliation': [], 'name': eachauthor, \n",
    "                       'familyName':authparse[0]}\n",
    "        else:\n",
    "            authdict = {'@type': 'outbreak:Person', 'affiliation': [], 'name': eachauthor}\n",
    "        authorlist.append(authdict)\n",
    "    return(authorlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the funding information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_funding_dict(funder,identifier=None):\n",
    "    fundict = {\"@type\": \"MonetaryGrant\",\n",
    "               \"funder\": {\"name\": funder},\n",
    "               \"name\": \"\"\n",
    "               }    \n",
    "    if identifier != None:\n",
    "        fundict[\"identifier\"]=identifier\n",
    "    return(fundict)\n",
    "\n",
    "def get_funding(soupobject):\n",
    "    fundersfield = soupobject.findAll(\"meta\", {\"name\":\"DC.contributor\"})\n",
    "    funders = get_meta_content(fundersfield)\n",
    "    fundercheck = len(fundersfield)\n",
    "    if fundercheck > 0:\n",
    "        identifiersfield = soupobject.findAll(\"meta\", {\"name\":\"DC.identifier\"}) \n",
    "        fundidlist = []\n",
    "        for eachitem in identifiersfield:\n",
    "            eachitemcontent = eachitem.get(\"content\")\n",
    "            if (\"https:\" in eachitemcontent) or (\"http:\" in eachitemcontent):\n",
    "                miscurls = eachitemcontent\n",
    "            else:\n",
    "                fundingid = eachitemcontent\n",
    "                fundidlist.append(fundingid)\n",
    "        fundlist = []\n",
    "        i=0\n",
    "        if len(funders)==len(fundidlist): ## There are the same amount of funders as ids\n",
    "            while i < len(funders):\n",
    "                fundict = generate_funding_dict(funders[i],fundidlist[i])\n",
    "                fundlist.append(fundict)\n",
    "                i=i+1\n",
    "        elif len(funders)>len(fundidlist): ## There are more funders than ids, map the MR ones, then ignore ids\n",
    "            mrfunds = [x for x in funders if \"MRC\" in x]\n",
    "            mrids = [x for x in fundidlist if \"MR\" in x]\n",
    "            while i < len(mrfunds):\n",
    "                fundict = generate_funding_dict(mrfunds[i],mrids[i])\n",
    "                fundlist.append(fundict)\n",
    "                i=i+1\n",
    "            remaining_funders = [x for x in funders if x not in mrfunds]\n",
    "            remaining_fundids = [x for x in fundidlist if x not in mrids]\n",
    "            j=0\n",
    "            if (len(remaining_fundids)==0) and (len(remaining_funders)>0):\n",
    "                while j<len(remaining_funders):\n",
    "                    fundict = generate_funding_dict(remaining_funders[j])\n",
    "                    fundlist.append(fundict)\n",
    "                    j=j+1\n",
    "        else: ##There are more ids than funders, and it will be impossible to map them\n",
    "            while i < len(funders):\n",
    "                fundict = generate_funding_dict(funders[i])\n",
    "                fundlist.append(fundict)\n",
    "                i=i+1            \n",
    "        fundflag = True\n",
    "    else:\n",
    "        fundlist = []\n",
    "        fundflag = False\n",
    "    return(fundlist, fundflag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are  46  urls to parse.\n",
      "retrieving record for  https://spiral.imperial.ac.uk:8443//handle/10044/1/78707\n",
      "parsing record\n",
      "transforming parsed record\n",
      "fetching the authors\n",
      "fetching the funders\n",
      "creating the json file\n",
      "presenting the results ... \n",
      "\n",
      "\n",
      "{'@context': {'schema': 'http://schema.org/', 'outbreak': 'https://discovery.biothings.io/view/outbreak/'}, '@type': 'Publication', 'journalName': 'Imperial College London', 'journalNameAbbreviation': 'imperialcollege', 'publicationType': 'Report', 'abstract': 'This briefing identifies key recovery policies that the UK government could introduce to both respond to the crisis of COVID-19, and support the country in meeting its commitment to reaching net-zero emissions by 2050.', 'name': 'A net-zero emissions economic recovery from COVID-19', 'datePublished': '2020-05-05', 'url': 'http://spiral.imperial.ac.uk/bitstream/10044/1/78707/2/COP26%20Universities%20Network%20Briefing%20-%20Economic%20Recovery%20from%20COVID-19.pdf', 'identifier': 'icl_78707', 'keywords': ['COVID-19', 'Climate change', 'Net zero', 'economy', 'Recovery', 'environment'], 'doi': '10.25561/78707', '_id': 'icl_78707', 'curatedBy': {'@type': 'Organization', 'identifier': 'imperialcollege', 'url': 'http://www.imperial.ac.uk/mrc-global-infectious-disease-analysis/covid-19/covid-19-reports/', 'name': 'MRC Centre for Global Infectious Disease Analysis', 'affiliation': ['Imperial College London'], 'curationDate': '2021-10-15'}, 'author': [{'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Allan, J', 'familyName': 'Allan'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Donovan, C', 'familyName': 'Donovan'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Ekins, P', 'familyName': 'Ekins'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Gambhir, A', 'familyName': 'Gambhir'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Hepburn, C', 'familyName': 'Hepburn'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Reay, D', 'familyName': 'Reay'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Robins, N', 'familyName': 'Robins'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Shuckburgh, E', 'familyName': 'Shuckburgh'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Zenghelis, D', 'familyName': 'Zenghelis'}]}\n",
      "\n",
      "\n",
      "starting next record ...\n",
      "\n",
      "\n",
      "retrieving record for  https://spiral.imperial.ac.uk:8443//handle/10044/1/84788\n",
      "parsing record\n",
      "transforming parsed record\n",
      "fetching the authors\n",
      "fetching the funders\n",
      "creating the json file\n",
      "presenting the results ... \n",
      "\n",
      "\n",
      "{'@context': {'schema': 'http://schema.org/', 'outbreak': 'https://discovery.biothings.io/view/outbreak/'}, '@type': 'Publication', 'journalName': 'Imperial College London', 'journalNameAbbreviation': 'imperialcollege', 'publicationType': 'Report', 'abstract': 'Summary Countries have deployed a wide range of policies to prioritize patients to hospital care to address unprecedent surges in demand during the course of the pandemic. Those policies included postponing planned hospital care for non-emergency cases and rationing critical care. We develop a model to optimally schedule elective hospitalizations and allocate hospital general and critical care beds to planned and emergency patients in England during the pandemic. We apply the model to NHS England data and show that optimized scheduling leads to lower years of life lost and costs than policies that reflect those implemented in England during the pandemic. Overall across all disease areas the model enables an extra 50,750 - 5,891,608 years of life gained when compared to standard policies, depending on the scenarios. Especially large gains in years of life are seen for neoplasms, diseases of the digestive system, and injuries & poisoning.', 'name': 'Report 40: Optimal scheduling rules for elective care to minimize years of life lost during the SARS-CoV-2 pandemic: an application to England', 'datePublished': '2020-12-10', 'url': 'http://spiral.imperial.ac.uk/bitstream/10044/1/84788/2/2020-12-10-COVID19-Report-40.pdf', 'identifier': 'icl_84788', 'keywords': ['COVID-19', 'COVID19', 'Coronavirus'], 'license': ['Â© 2020 The Author(s). This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives\\r\\n4.0 International License https://creativecommons.org/licenses/by-nc-nd/4.0/.', 'https://creativecommons.org/licenses/by-nc-nd/4.0/'], 'doi': '10.25561/84788', '_id': 'icl_84788', 'curatedBy': {'@type': 'Organization', 'identifier': 'imperialcollege', 'url': 'http://www.imperial.ac.uk/mrc-global-infectious-disease-analysis/covid-19/covid-19-reports/', 'name': 'MRC Centre for Global Infectious Disease Analysis', 'affiliation': ['Imperial College London'], 'curationDate': '2021-10-15'}, 'author': [{'@type': 'outbreak:Person', 'affiliation': [], 'name': \"D'Aeth, J\", 'familyName': \"D'Aeth\"}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Ghosal, S', 'familyName': 'Ghosal'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Grimm, F', 'familyName': 'Grimm'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Haw, D', 'familyName': 'Haw'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Koca, E', 'familyName': 'Koca'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Lau, K', 'familyName': 'Lau'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Moret, S', 'familyName': 'Moret'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Rizmie, D', 'familyName': 'Rizmie'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Deeny, S', 'familyName': 'Deeny'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Perez Guzman, P', 'familyName': 'Perez Guzman'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Ferguson, N', 'familyName': 'Ferguson'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Hauck, K', 'familyName': 'Hauck'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Smith, P', 'familyName': 'Smith'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Wiesemann, W', 'familyName': 'Wiesemann'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Forchini, G', 'familyName': 'Forchini'}, {'@type': 'outbreak:Person', 'affiliation': [], 'name': 'Miraldo, M', 'familyName': 'Miraldo'}], 'funding': [{'@type': 'MonetaryGrant', 'funder': {'name': 'Medical Research Council (MRC)'}, 'name': '', 'identifier': 'MR/R015600/1'}, {'@type': 'MonetaryGrant', 'funder': {'name': 'Abdul Latif Jameel Foundation'}, 'name': ''}]}\n",
      "\n",
      "\n",
      "starting next record ...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reports_url = 'https://spiral.imperial.ac.uk:8443/handle/10044/1/78555/simple-search?location=10044%2F1%2F78555&query=&filter_field_1=type&filter_type_1=equals&filter_value_1=Report&rpp=100&sort_by=score&order=DESC&etal=1&submit_search=Update'\n",
    "url_list = get_report_links(reports_url)\n",
    "print(\"there are \",len(url_list),\" urls to parse.\")\n",
    "curatedBy = create_curationObject()\n",
    "\n",
    "## Pull the metadata from each report link and throw it into a dictionary\n",
    "for each_url in url_list[0:2]:\n",
    "    print(\"retrieving record for \",each_url)\n",
    "    record_result = requests.get(each_url)\n",
    "    print(\"parsing record\")\n",
    "    parsed_record = BeautifulSoup(record_result.text, \"html.parser\")\n",
    "    print(\"transforming parsed record\")\n",
    "    base_info = transform_pub_meta(parsed_record)\n",
    "    base_info[\"curatedBy\"] = curatedBy\n",
    "    print(\"fetching the authors\")\n",
    "    author_list = get_authors(parsed_record)\n",
    "    print(\"fetching the funders\")\n",
    "    fund_list, fund_flag = get_funding(parsed_record)\n",
    "    ## Create the Json\n",
    "    print(\"creating the json file\")\n",
    "    base_info[\"author\"] = author_list\n",
    "    if fund_flag == True:\n",
    "        base_info[\"funding\"] = fund_list\n",
    "    print(\"presenting the results ... \")\n",
    "    print(\"\\n\")\n",
    "    print(base_info)\n",
    "    print(\"\\n\")\n",
    "    print(\"starting next record ...\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fundersfield = parsed_record.findAll(\"meta\", {\"name\":\"DC.contributor\"})\n",
    "funders = get_meta_content(fundersfield)\n",
    "fundercheck = len(fundersfield)\n",
    "identifiersfield = parsed_record.findAll(\"meta\", {\"name\":\"DC.identifier\"})\n",
    "if fundercheck > 0:\n",
    "    identifiersfield = parsed_record.findAll(\"meta\", {\"name\":\"DC.identifier\"}) \n",
    "    fundidlist = []\n",
    "    for eachitem in identifiersfield:\n",
    "        eachitemcontent = eachitem.get(\"content\")\n",
    "        if (\"https:\" in eachitemcontent) or (\"http:\" in eachitemcontent):\n",
    "            miscurls = eachitemcontent\n",
    "        else:\n",
    "            fundingid = eachitemcontent\n",
    "            fundidlist.append(fundingid)\n",
    "    fundlist = []\n",
    "    i=0\n",
    "    if len(funders)==len(fundidlist):\n",
    "        while i < len(funders):\n",
    "            fundict = generate_funding_dict(funders[i],fundidlist[i])\n",
    "            fundlist.append(fundict)\n",
    "            i=i+1\n",
    "    elif len(funders)>len(fundidlist):\n",
    "        mrfunds = [x for x in funders if \"MRC\" in x]\n",
    "        mrids = [x for x in fundidlist if \"MR\" in x]\n",
    "        while i < len(mrfunds):\n",
    "            fundict = generate_funding_dict(mrfunds[i],mrids[i])\n",
    "            fundlist.append(fundict)\n",
    "            i=i+1\n",
    "        remaining_funders = [x for x in funders if x not in mrfunds]\n",
    "        remaining_fundids = [x for x in fundidlist if x not in mrids]\n",
    "        print(remaining_funders,len(remaining_funders))\n",
    "        print(remaining_fundids,len(remaining_fundids))\n",
    "        j=0\n",
    "        if (len(remaining_fundids)==0) and (len(remaining_funders)>0):\n",
    "            while j<len(remaining_funders):\n",
    "                fundict = generate_funding_dict(remaining_funders[j])\n",
    "                fundlist.append(fundict)\n",
    "                j=j+1                         \n",
    "    fundflag = True\n",
    "else:\n",
    "    fundlist = []\n",
    "    fundflag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parsed_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_url in url_list[1:2]:\n",
    "    record_result = requests.get(each_url)\n",
    "    parsed_record = BeautifulSoup(record_result.text, \"html.parser\")\n",
    "    base_info = transform_pub_meta(parsed_record)\n",
    "    base_info[\"curatedBy\"] = curatedBy\n",
    "    author_list = get_authors(parsed_record)\n",
    "    print(\"fetching the funders\")\n",
    "    #fund_list, fund_flag = get_funding(parsed_record)\n",
    "    fundersfield = parsed_record.findAll(\"meta\", {\"name\":\"DC.contributor\"})\n",
    "    funders = get_meta_content(fundersfield)\n",
    "    fundercheck = len(fundersfield)\n",
    "    if fundercheck > 0:\n",
    "        identifiersfield = parsed_record.findAll(\"meta\", {\"name\":\"DC.identifier\"}) \n",
    "        fundidlist = []\n",
    "        for eachitem in identifiersfield:\n",
    "            eachitemcontent = eachitem.get(\"content\")\n",
    "            if (\"https:\" in eachitemcontent) or (\"http:\" in eachitemcontent):\n",
    "                miscurls = eachitemcontent\n",
    "            else:\n",
    "                fundingid = eachitemcontent\n",
    "                fundidlist.append(fundingid)\n",
    "        fundlist = []\n",
    "        i=0\n",
    "        while i < len(funders):\n",
    "            fundict = {\"@type\": \"MonetaryGrant\",\n",
    "                       \"funder\": {\n",
    "                       \"name\": funders[i]\n",
    "                       },\n",
    "                      \"identifier\": fundidlist[i],\n",
    "                      \"name\": \"\"\n",
    "            }\n",
    "            fundlist.append(fundict)\n",
    "        fundflag = True\n",
    "    else:\n",
    "        fundlist = []\n",
    "        fundflag = False\n",
    "\"\"\"   \n",
    "    ## Create the Json\n",
    "    print(\"creating the json file\")\n",
    "    base_info[\"author\"] = author_list\n",
    "    if fund_flag == True:\n",
    "        base_info[\"funding\"] = fund_list\n",
    "    print(\"presenting the results ... \")\n",
    "    print(\"\\n\")\n",
    "    print(base_info)\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
